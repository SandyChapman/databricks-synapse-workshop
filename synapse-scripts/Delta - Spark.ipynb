{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Synapse Databricks Streaming Demo\n",
        "\n",
        "In this notebook, we'll illustrate two examples:\n",
        "\n",
        "1. Reading a Delta table in Synapse\n",
        "2. Spark Streaming in Synapse and how it can leverage streams started in Databricks.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Show how a delta format dataset can be loaded and displayed\n",
        "container_name = 'synstorage'\n",
        "storage_account_name = 'strdbwsynworkshop'\n",
        "df = spark.read.format('delta').load(f'abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/delta_test')\n",
        "display(df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 2: Delta streaming. \n",
        "\n",
        "This example has two streams: \n",
        "\n",
        "(a) a readStream from a Delta table in ADLS; and \n",
        "\n",
        "(b) a writeStream to a new Delta table in ADLS\n",
        "\n",
        "Between these two steps, we'll add a small transformation to show how the streams \n",
        "can be adjusted."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2\n",
        "container_name = 'synstorage'\n",
        "storage_account_name = 'strdbwsynworkshop'\n",
        "delta_streaming_path = f'abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/delta_test_partitioned_stream'\n",
        "delta_streaming_path_output = f'abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/delta_test_partitioned_stream_synapse'\n",
        "\n",
        "df_stream = (\n",
        "    # Create a read stream from delta format\n",
        "    spark.readStream.format('delta').load(delta_streaming_path)\n",
        "    # Apply a rename transformation\n",
        "    .withColumnRenamed('a', 'new_a')\n",
        "    # Write new stream as a new Delta dataset in ADLS\n",
        "    .writeStream.format(\"delta\").outputMode(\"append\")\n",
        "    .option(\"checkpointLocation\", \"/delta_test_partitioned_stream_synapse_checkpoint\")\n",
        "    .start(delta_streaming_path_output)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream data cannot be viewed in Synapse, however, we can see the status info\n",
        "# on the Spark stream.\n",
        "print(df_stream.isActive)\n",
        "print(df_stream.status)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We stop the stream when we're done with it.\n",
        "df_stream.stop()\n",
        "print(df_stream.isActive)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}